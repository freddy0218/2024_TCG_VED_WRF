{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a464b17d-266a-4e05-b2d9-6b2331faea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"──────────────────────────────────────────────────────────────────────────┐\n",
    "│ Loading necessary libraries to build and train model                       │\n",
    "└──────────────────────────────────────────────────────────────────────────\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import os,sys,gc\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import proplot as plot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "import properscoring as ps\n",
    "from copy import deepcopy\n",
    "plot.rc.update({'figure.facecolor':'w','axes.labelweight':'ultralight',\n",
    "                'tick.labelweight':'ultralight','gridminor.linestyle':'--','title.weight':'normal','linewidth':0.5})\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dd0e80-795b-42b8-83dd-4134268be510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/')\n",
    "from util.ml import (preproc,vae)\n",
    "from util.wrf_process import (read_and_write)\n",
    "import read_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c454662-e7e9-4137-871e-ab7f1b2f32e1",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554cb371-26b3-4f3a-9ae3-7da28ba87748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class proc_X:\n",
    "    def __init__(self,X,PCA):\n",
    "        self.X=X\n",
    "        self.PCA=PCA\n",
    "        \n",
    "    def myPCA_projection_sen(self,varname,toproj_flatvar,orig_flatvar):\n",
    "        projvar_transformed = np.dot(toproj_flatvar-np.nanmean(orig_flatvar,axis=0),self.PCA[varname].components_.T)\n",
    "        return projvar_transformed\n",
    "\n",
    "    def create_timeseries(self,varname):\n",
    "        Xtrain,Xvalid,Xtest = self.X['train'], self.X['valid'], self.X['test']\n",
    "        train = self.PCA[varname].transform(Xtrain[varname])\n",
    "        valid = self.myPCA_projection_sen(varname,Xvalid[varname],Xtrain[varname])\n",
    "        test = self.myPCA_projection_sen(varname,Xtest[varname],Xtrain[varname])\n",
    "        return {'train':train,'valid':valid,'test':test}\n",
    "\n",
    "    def normalize_timeseries(self,timeseries=None,category='train'):\n",
    "        #assert timeseries['u'].shape[-1]==26,\"var shape error\"\n",
    "        output = np.zeros_like(timeseries[category])\n",
    "        for le in range(timeseries[category].shape[1]):\n",
    "            trainmean,trainstd = np.nanmean(timeseries['train'][:,le]), np.nanstd(timeseries['train'][:,le])\n",
    "            output[:,le] = (timeseries[category][:,le]-trainmean)/trainstd\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a90694-eadd-4dd3-acf0-00c7f29ba07d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0_3'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[0].split('/')[-1][int(17):].split('.')[0]\n",
    "#sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f66121-8841-47d4-9e47-9993e482f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0033359527587890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3375ff9755054933acd92aa64c19a603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm([1,18]):#range(len(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xsmooth9100*'))))[:]):\n",
    "    X = read_and_write.depickle(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xsmooth9100*'))[i])\n",
    "    validindices = sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xsmooth9100*'))[i].split('/')[-1].split('.')[0][12:]\n",
    "    PCA = read_and_write.depickle(sorted(glob.glob('../../storage/proc/PCA/PCAsmooth9100*'))[i])\n",
    "    y = read_and_write.depickle(sorted(glob.glob('../../storage/proc/y*'))[i])\n",
    "    \n",
    "    LWs = proc_X(X,PCA['PCA']).create_timeseries('LW')\n",
    "    SWs = proc_X(X,PCA['PCA']).create_timeseries('SW')\n",
    "    LWstop = np.abs(PCA['PCA']['LW'].explained_variance_ratio_.cumsum()-0.5).argmin()\n",
    "    SWstop = np.abs(PCA['PCA']['SW'].explained_variance_ratio_.cumsum()-0.8).argmin()\n",
    "    \n",
    "    LWs_norml = {'train':proc_X(X,PCA['PCA']).normalize_timeseries(LWs,'train')[:,:LWstop],\n",
    "                 'valid':proc_X(X,PCA['PCA']).normalize_timeseries(LWs,'valid')[:,:LWstop],\n",
    "                 'test':proc_X(X,PCA['PCA']).normalize_timeseries(LWs,'test')[:,:LWstop]}\n",
    "    SWs_norml = {'train':proc_X(X,PCA['PCA']).normalize_timeseries(SWs,'train')[:,:SWstop],\n",
    "                 'valid':proc_X(X,PCA['PCA']).normalize_timeseries(SWs,'valid')[:,:SWstop],\n",
    "                 'test':proc_X(X,PCA['PCA']).normalize_timeseries(SWs,'test')[:,:SWstop]}\n",
    "    Xtrain = np.concatenate([LWs_norml['train'],SWs_norml['train']],axis=1)\n",
    "    Xvalid = np.concatenate([LWs_norml['valid'],SWs_norml['valid']],axis=1)\n",
    "    Xtest = np.concatenate([LWs_norml['test'],SWs_norml['test']],axis=1)\n",
    "    read_and_write.save_to_pickle({'train':Xtrain,'valid':Xvalid,'Xtest':Xtest},f'../../storage/proc/Xsmooth/9100/Xtimeseries_{validindices}.pkl')\n",
    "    del X,PCA,y,Xtrain,Xvalid,Xtest\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644f172-08ed-43a3-a295-581b07a83f7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train VED: Get best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37106678-8d4f-4f94-8ef7-b3a1e434a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    models,losses = [],[]\n",
    "    model = vae.VAE(nummem[-2],nummem[-1],1,1,1,nummem)\n",
    "    #droprate = trial.suggest_float(\"droprate\",0.05,0.45)\n",
    "    lr = trial.suggest_float(\"lr\",1e-6,1e-3)#,log=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    criterion = vae.vae_loss\n",
    "    n_epochs = 10000\n",
    "    scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-8, max_lr=1e-4,cycle_momentum=False)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=1e-12)\n",
    "\n",
    "    schedulerCY,schedulerLS = scheduler2,scheduler\n",
    "\n",
    "    l2_lambda = trial.suggest_float(\"l2_lambda\",0.01,0.02)\n",
    "    #model,loss = train_model(model=model,train_data=data_loaders['train'],val_data=data_loaders['val'],optimizer=optimizer,scheduler=[scheduler,scheduler2],numepochs=num_epochs,early_stopper=None,variance_store=None,\\\n",
    "    #                         lossfunc=lossfuncs[0],regularization='L2',l1_lambda=0.1,l2_lambda=l2_lambda,trial=trial)\n",
    "    #torch.save(model,'../tmp/bayesian/saved_model.8.'+str(trial.number)+'.pt')\n",
    "    # Define Loss, Optimizer\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "            reconX,mu1,logvar1,mu2,logvar2 = model(features)\n",
    "            batch_loss,_,_ = vae.vae_loss(reconX, labels.unsqueeze(1),mu1,logvar1,mu2,logvar2,losscoeff)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            schedulerCY.step()\n",
    "            loss += batch_loss.item()\n",
    "        loss = loss/len(train_loader)\n",
    "        train_losses.append(loss)\n",
    "        criterion = vae.vae_loss\n",
    "        val_loss,_,_ = vae.eval_model(model,\n",
    "                              val_loader,\n",
    "                              criterion,\n",
    "                             l2_lambda,\n",
    "                                  losscoeff)\n",
    "        schedulerLS.step(val_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if epoch%1000 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, n_epochs))\n",
    "            print(\"Loss: {:.4f}\".format(loss))\n",
    "        #if val_loss <= min(val_losses):\n",
    "        #    torch.save(model,'best_model'+str(trial.number))\n",
    "    #torch.save(model,'./tmp/bayesian/best_model.8.'+str(trial.number)+'.pt')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b400b5-831d-4d3a-b619-7c44d6eadf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/proc/VEDsmooth_9100/0_3/losscoeff_0/bestparams.pkt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/'\n",
    "suffix+'proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[i].split('/')[-1][22:].split('.')[0])+'/losscoeff_0/'+'bestparams.pkt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce94edc-5e03-42b7-a4ee-da7fb5adc9b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(461, 15) (425,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aaaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3026023/3025954928.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maaaa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvalidindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mLWstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PCA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LW'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aaaa' is not defined"
     ]
    }
   ],
   "source": [
    "#for i in range(len(sorted(glob.glob('../../storage/proc/X*pkl'))[:2])):\n",
    "for i in [1]:#range(len(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[1:3])):\n",
    "    print(i)\n",
    "    PCA = read_and_write.depickle(sorted(glob.glob('../../storage/proc/PCA/PCAsmooth9100*'))[i])\n",
    "    X = read_and_write.depickle(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[i])\n",
    "    y = read_and_write.depickle(sorted(glob.glob('../../storage/proc/y*'))[i])\n",
    "    X['test'] = X.pop('Xtest')\n",
    "    print(X['train'].shape,y['train'].shape)\n",
    "\n",
    "    print(aaaa)\n",
    "    validindices = sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[i].split('/')[-1][22:].split('.')[0]\n",
    "    LWstop = np.abs(PCA['PCA']['LW'].explained_variance_ratio_.cumsum()-0.5).argmin()\n",
    "    SWstop = np.abs(PCA['PCA']['SW'].explained_variance_ratio_.cumsum()-0.8).argmin()\n",
    "\n",
    "    train_data,val_data,test_data = preproc.prepare_tensors(X,y,'No')\n",
    "    batch_size = 10\n",
    "    num_workers = 2\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    del PCA,X,y\n",
    "    gc.collect()\n",
    "    \n",
    "    import optuna\n",
    "    nummem = [0,LWstop,SWstop]\n",
    "    losscoeff=1\n",
    "    study = optuna.create_study(directions=[\"minimize\"])\n",
    "    study.optimize(objective, n_trials=6)#, timeout=300)\n",
    "\n",
    "    suffix = '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/storage'\n",
    "    #os.makedirs(suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*'))[i].split('/')[-1][12:].split('.')[0]))\n",
    "    #os.makedirs(suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*'))[i].split('/')[-1][12:].split('.')[0])+'/losscoeff_0/')\n",
    "    if losscoeff==1.0:\n",
    "        losscoeff2 = int(losscoeff)\n",
    "        read_and_write.save_to_pickle(study,\n",
    "                                      suffix+'/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[i].split('/')[-1][22:].split('.')[0])+\n",
    "                                      '/losscoeff_0/'+'bestparams.pkt')\n",
    "        for losscoeff in [0.9,0.65,0.55,0.45,0.35,0.3,0.25,0.95,0.85,0.8,0.75,0.7,0.6,0.5,0.4]:\n",
    "            read_and_write.save_to_pickle(study,suffix+'/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[i].split('/')[-1][22:].split('.')[0])+\n",
    "                                          '/losscoeff_'+str(losscoeff)+'/'+'bestparams.pkt')\n",
    "    else:\n",
    "        read_and_write.save_to_pickle(study,suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*pkl'))[i].split('/')[-1][22:].split('.')[0])+'/losscoeff_0/'+'bestparams.pkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f5298e6-ebb1-497a-8c01-4e22e0ea4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "PCA = read_and_write.depickle(sorted(glob.glob('../../storage/proc/PCA/PCA*'))[i])\n",
    "X = read_and_write.depickle(sorted(glob.glob('../../storage/proc/Xtimeseries*'))[i])\n",
    "y = read_and_write.depickle(sorted(glob.glob('../../storage/proc/y*'))[i])\n",
    "X['test'] = X.pop('Xtest')\n",
    "    \n",
    "validindices = sorted(glob.glob('../../storage/proc/X*pkl'))[i].split('/')[-1][12:].split('.')[0]\n",
    "LWstop = np.abs(PCA['PCA']['LW'].explained_variance_ratio_.cumsum()-0.5).argmin()\n",
    "SWstop = np.abs(PCA['PCA']['SW'].explained_variance_ratio_.cumsum()-0.8).argmin()\n",
    "\n",
    "train_data,val_data,test_data = prepare_tensors(X,y,'No')\n",
    "batch_size = 5\n",
    "num_workers = 2\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "del PCA,X,y\n",
    "gc.collect()\n",
    "    \n",
    "nummem = [0,LWstop,SWstop]\n",
    "losscoeff=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77b9bde2-7345-4ebb-8a92-d58bb92b4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = read_and_write.depickle(suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*pkl'))[i].split('/')[-1][12:].split('.')[0])+'/losscoeff_0/'+'bestparams.pkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "633d1e9b-62f4-41bc-9932-c6e59349bac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0037660598754882812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 23,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3000b9a8b444efda32e38922d224478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9.85142297907309, 9.222853348805355)\n",
      "(5.639664442701773, 5.772621237314665)\n",
      "(5.068732455542142, 5.500547092694503)\n",
      "(5.050715463235974, 5.640253332945017)\n",
      "(4.890204999934543, 5.495082222498381)\n",
      "(4.846279404041442, 5.629986299918248)\n",
      "(4.709101298315958, 5.655073184233445)\n",
      "(4.642548099160194, 5.430186977753272)\n",
      "(4.660028381103819, 5.504338076481452)\n",
      "(4.674208345738324, 5.378917817886059)\n",
      "(4.6938084248792045, 5.492722066549154)\n",
      "(4.619749583303928, 5.486359866765829)\n",
      "(9.25029461763122, 8.617649371807392)\n",
      "(5.525918946178122, 5.7201358538407545)\n",
      "(5.181089271198619, 5.4639218266193685)\n",
      "(4.9638013697483325, 5.531228909125695)\n",
      "(4.946268291635946, 5.423445513615241)\n",
      "(4.749122809280049, 5.729436076604403)\n",
      "(4.768325078216466, 5.5084604277060585)\n",
      "(4.779350396838378, 5.470411873780764)\n",
      "(4.643695956604048, 5.4870196626736565)\n",
      "(4.613083222372965, 5.562157786809481)\n",
      "(4.648070892149752, 5.478477196051524)\n",
      "(8.29459180005572, 7.3197731421544)\n",
      "(5.588655034249479, 5.591867497334113)\n",
      "(5.108101380819624, 5.557354372281295)\n",
      "(4.948377139189026, 5.598963622863476)\n",
      "(4.920541008087722, 5.581367666904743)\n",
      "(4.828407318585298, 5.526783282940205)\n",
      "(4.800234447148713, 5.427490931290847)\n",
      "(4.6862209791486915, 5.594523069950251)\n",
      "(4.628334268927574, 5.460355790761801)\n",
      "(4.620622766458175, 5.599724031411684)\n",
      "(6.251407039436427, 5.913151355890127)\n",
      "(5.426191598176956, 5.477452333156879)\n",
      "(5.2154884138567885, 5.507793169755202)\n",
      "(4.958076329732483, 5.352009094678438)\n",
      "(4.897336506708101, 5.453981704436815)\n",
      "(4.907754058526321, 5.469517327271975)\n",
      "(4.734015727585012, 5.6400914788246155)\n",
      "(4.707082354886965, 5.461123471076672)\n",
      "(4.707983734932813, 5.5682343657200155)\n",
      "(6.308784197677266, 5.71536982517976)\n",
      "(5.363225130364299, 5.295692368195607)\n",
      "(5.200302708555352, 5.378537856615507)\n",
      "(4.929153014313091, 5.47043089224742)\n",
      "(4.87673843042417, 5.542393551422999)\n",
      "(4.891004130921581, 5.484117975601783)\n",
      "(4.813840934498743, 5.411054111444033)\n",
      "(4.639914287084883, 5.319605070811051)\n",
      "(7.303984458473596, 7.155279278755188)\n",
      "(5.48533923517574, 5.569979099126963)\n",
      "(5.093304001810876, 5.558344481083063)\n",
      "(5.018920848315412, 5.499040846641247)\n",
      "(4.877134109762582, 5.437547193123744)\n",
      "(4.832427467473528, 5.566695598455576)\n",
      "(4.741521611471068, 5.544509057815258)\n",
      "(4.783078414472667, 5.503011854795309)\n",
      "(4.680130337449637, 5.599189888972503)\n",
      "(4.6823419291864745, 5.526911270159942)\n",
      "(4.619557745077393, 5.536655515432358)\n",
      "(4.611992682245645, 5.616744990532215)\n",
      "(4.544743989678946, 5.5246213514071245)\n",
      "(7.436576324430379, 6.799246577116159)\n",
      "(5.548061496832154, 5.494119048118591)\n",
      "(5.143979070877487, 5.474770160821768)\n",
      "(4.940609717233614, 5.569321435231429)\n",
      "(4.85096879506653, 5.427854703022883)\n",
      "(4.880434740673412, 5.4473208005611715)\n",
      "(4.762572094459426, 5.43717346741603)\n",
      "(4.734182637523521, 5.605047083817995)\n",
      "(4.642489840530536, 5.568024114920543)\n",
      "(4.6428948762741955, 5.603176770301966)\n",
      "(4.6273061883720485, 5.376573250843928)\n",
      "(4.519157181409272, 5.463200461405974)\n",
      "(8.348741951313885, 7.213035996143635)\n",
      "(5.599017656662247, 5.680260864587931)\n",
      "(5.141564744439992, 5.374430713745264)\n",
      "(5.111719459295273, 5.4609292562191305)\n",
      "(4.8907383409413425, 5.361577437474177)\n",
      "(4.7989760637283325, 5.3771570187348585)\n",
      "(4.778508340770548, 5.4645790457725525)\n",
      "(4.684504987163977, 5.417269236766375)\n",
      "(4.724776074967601, 5.451213955879211)\n",
      "(4.6500903991135685, 5.455156234594492)\n",
      "(8.491898282007737, 8.58842081290025)\n",
      "(5.578198128803209, 5.63901026890828)\n",
      "(5.32012239979072, 5.530921271214118)\n",
      "(4.9967024536295375, 5.488702627328726)\n",
      "(4.875496754592115, 5.498327035170335)\n",
      "(4.787504590370438, 5.500988891491523)\n",
      "(4.769070778719404, 5.44360553759795)\n",
      "(4.764340371570804, 5.540185139729426)\n",
      "(4.674446134404703, 5.501909187206855)\n"
     ]
    }
   ],
   "source": [
    "times = ['exp1a','exp1b','exp1c','exp1d','exp1e','exp1f','exp1g','exp1h','exp1i']\n",
    "#times = ['exp1e','exp1f','exp1g','exp1h','exp1i']#,'exp1d','exp1e']\n",
    "for i in tqdm(range(len(times))):\n",
    "    models,losses = [],[]\n",
    "    model = vae.VAE(nummem[-2],nummem[-1],1,1,1,nummem)\n",
    "    optimizers = [torch.optim.Adam(model.parameters(), lr=study.best_params['lr'])]#, optim.AdaBound(model.parameters(),lr=1e-7)] 1e-6 [torch.optim.Adam(model.parameters(),lr=0.5e-5),torch.optim.SGD(model.parameters(),lr=0.5e-5,momentum=0.8)]\n",
    "    loss = torch.nn.L1Loss()\n",
    "    for optimizer in optimizers:\n",
    "        scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.5e-8, max_lr=7e-5,cycle_momentum=False) #1e-9/1e-5\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=1e-12)  #1e-18\n",
    "        num_epochs = 1000*40#26\n",
    "        #early_stopper = ts_models.EarlyStopping(patience=250, verbose=False, delta=1e-5, path='checkpoint.pt', trace_func=print)#EarlyStopper(patience=8, min_delta=1e-3)\n",
    "        early_stopper = vae.EarlyStopping(patience=2000, verbose=False, delta=1.5e-5, path='checkpoint.pt', trace_func=print)\n",
    "        #variance_store = [varu,varv,varw,varth]\n",
    "        #variance_store = [varu,varv,varth]\n",
    "        model,loss,_ = vae.train_model(model=model,optimizer=optimizer,scheduler=[scheduler,scheduler2],numepochs=num_epochs,early_stopper=early_stopper,variance_store=None,\\\n",
    "                                         lossfunc=loss,train_loader=train_loader,val_loader=val_loader,test_loader=test_loader,l2_lambda=study.best_params['l2_lambda'],count=10,vaeloss_coeff=losscoeff)\n",
    "        models.append(model)\n",
    "        losses.append(loss)\n",
    "    #torch.save(models, '../tmp/torch_try/ts/'+str(expname)+'/0/'+'models'+str(splitnum)+'_'+str(expname)+'3dnonln_1115_'+str(times[i])+'.pt')\n",
    "    #read_and_proc.save_to_pickle('../tmp/torch_try/ts/'+str(expname)+'/0/'+'losses'+str(splitnum)+'_'+str(expname)+'3dnonln_1115_'+str(times[i])+'.pkt',losses,'PICKLE')\n",
    "    if losscoeff==1.0:\n",
    "        losscoeff2 = int(losscoeff)\n",
    "        torch.save(models,suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*pkl'))[0].split('/')[-1][12:].split('.')[0])+'/losscoeff_0/'+'modelstest_vae_'+str(times[i])+'.pk')\n",
    "        read_and_write.save_to_pickle(losses,suffix+'/proc/VED/'+str(sorted(glob.glob('../../storage/proc/X*pkl'))[0].split('/')[-1][12:].split('.')[0])+'/losscoeff_0/'+'lossestest_vae_'+str(times[i])+'.pkt')\n",
    "    else:\n",
    "        torch.save(models,filepath+'vae/losscoeff_'+str(losscoeff)+'/'+str(splitnum)+'/modelstest'+str(splitnum)+'_vae_'+str(times[i])+'.pk')\n",
    "        read_and_write.save_to_pickle(filepath+'vae/losscoeff_'+str(losscoeff)+'/'+str(splitnum)+'/lossestest'+str(splitnum)+'_vae_'+str(times[i])+'.pkt',losses,'PICKLE')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2660b3d-4b3c-4e44-90a7-bcc4cf789482",
   "metadata": {},
   "source": [
    "# VED: resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17f09f2c-9f55-49fc-a15b-22fd924abfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set = read_config.read_config('../../config.ini')\n",
    "startname = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caf75a34-51d9-4781-8e90-2e4e2ddab3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/storage/proc/VED/0_6/losscoeff_0.95/lossestest_vae_exp1b.pkt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copy('/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/storage/proc/VED/0_6/losscoeff_0/lossestest_vae_exp1b.pkt',\n",
    "            '/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/storage/proc/VED/0_6/losscoeff_0.95/lossestest_vae_exp1b.pkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836ca755-a1fd-4d06-812b-4374cae66d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_set = read_config.read_config('../../config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d263c6da-c647-4750-9136-0997570d9695",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_410678/603466201.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuffix\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'storage/proc/VEDsmooth_9100/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../storage/proc/Xsmooth/9100/Xtimeseries*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m'/losscoeff_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'modelstest_vae_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../storage/proc/Xsmooth/9100/Xtimeseries*'))[1].split('/')[-1][startname:].split('.')[0])+\\\n",
    "'/losscoeff_'+str(0.95)+'/'+'modelstest_vae_'+str(exp)+'.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d2a43cc-9b89-4a0d-93db-e647a6fa0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resume_training:\n",
    "    def __init__(self,splitnum=None,droprate=None,nonln_num=None,timelag=None,batch_size=None,num_workers=2):\n",
    "        self.splitnum=splitnum\n",
    "        self.droprate=droprate\n",
    "        self.vaeloss_coeff=nonln_num\n",
    "        self.timelag = timelag\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers=2\n",
    "        \n",
    "    def get_data(self,suffix='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/',config_set=config_set):\n",
    "        #PCA = read_and_write.depickle(sorted(glob.glob(suffix+'storage/proc/PCA/PCA*'))[self.splitnum])\n",
    "        X = read_and_write.depickle(sorted(glob.glob(suffix+'storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum])\n",
    "        y = read_and_write.depickle(sorted(glob.glob(suffix+'storage/proc/y*'))[self.splitnum])\n",
    "        X['test'] = X.pop('Xtest')\n",
    "        \n",
    "        validindices = sorted(glob.glob(suffix+'storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0]\n",
    "        brchindex = read_and_write.depickle(suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\\\n",
    "                                        '/losscoeff_0'+'/'+'nummem.pkl')\n",
    "        #LWstop = np.abs(PCA['PCA']['LW'].explained_variance_ratio_.cumsum()-float(config_set['ML_LWnumcomps'])).argmin()\n",
    "        #SWstop = np.abs(PCA['PCA']['SW'].explained_variance_ratio_.cumsum()-float(config_set['ML_SWnumcomps'])).argmin()\n",
    "        train_data,val_data,test_data = preproc.prepare_tensors(X,y,'No')\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=self.batch_size,shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(dataset=val_data,batch_size=self.batch_size,shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(dataset=test_data,batch_size=self.batch_size,shuffle=False)\n",
    "        return train_loader,val_loader,test_loader,brchindex#[0,LWstop,SWstop]\n",
    "    \n",
    "    def continue_training(self,suffix='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/',config_set=None,exp='e',scheduler_lr=[1e-14,5e-10],early_stopper=None):\n",
    "        i=self.splitnum\n",
    "        train_loader,val_loader,_,brchindex = self.get_data(config_set=config_set)\n",
    "        study = read_and_write.depickle(suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\\\n",
    "                                        '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'bestparams.pkt')\n",
    "        original_model = vae.VAE(brchindex[-2],brchindex[-1],1,1,1,brchindex)\n",
    "        #######################################################################################################################################\n",
    "        # Transfer state dict\n",
    "        pretrained_model = torch.load(suffix+'storage/proc/VEDsmooth_9100/'+\\\n",
    "                                      str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\\\n",
    "                                      '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'modelstest_vae_'+str(exp)+'.pk')[0]\n",
    "        model_dict = original_model.state_dict()\n",
    "        pretrained_dict = pretrained_model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict)\n",
    "        original_model.load_state_dict(model_dict)\n",
    "        #######################################################################################################################################\n",
    "        #######################################################################################################################################\n",
    "        optimizer = torch.optim.Adam(original_model.parameters(), lr=study.best_params['lr'])\n",
    "        #lossfunc = torch.nn.L1Loss()\n",
    "        #scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-16, max_lr=5e-10,cycle_momentum=False) #1e-9/1e-5\n",
    "        scheduler2 = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=scheduler_lr[0], max_lr=scheduler_lr[1],cycle_momentum=False) #1e-9/1e-5\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',min_lr=1e-20)\n",
    "        #######################################################################################################################################\n",
    "        \n",
    "        lowest_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        schedulerCY,schedulerLS = scheduler2,scheduler\n",
    "        train_losses,trainrecon_losses,trainkl_losses = [],[],[]\n",
    "        val_losses,valrecon_losses,valkl_losses = [],[],[]\n",
    "        \n",
    "        for epoch in tqdm(range(20000)):\n",
    "            original_model.train()\n",
    "            train_loss = 0\n",
    "            trainrecon_loss = 0\n",
    "            trainkl_loss = 0\n",
    "            # Training loop here\n",
    "            for features, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                reconX,mu1,logvar1,mu2,logvar2 = original_model(features)\n",
    "                batch_loss,recon_loss,kl_loss = vae.vae_loss(reconX, labels.unsqueeze(1),mu1,logvar1,mu2,logvar2,self.vaeloss_coeff)\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                schedulerCY.step()\n",
    "                \n",
    "                train_loss += batch_loss.item() \n",
    "                trainrecon_loss += recon_loss.item()\n",
    "                trainkl_loss += kl_loss.item()\n",
    "                \n",
    "            train_loss = train_loss / len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            trainrecon_loss = trainrecon_loss / len(train_loader)\n",
    "            trainrecon_losses.append(trainrecon_loss)\n",
    "            trainkl_loss = trainkl_loss / len(train_loader)\n",
    "            trainkl_losses.append(trainkl_loss)\n",
    "\n",
    "            # Validation loop\n",
    "            original_model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                val_reconloss = 0\n",
    "                val_klloss = 0\n",
    "                val_loss,val_reconloss,val_klloss = 0,0,0\n",
    "                for features, labels in val_loader:\n",
    "                    reconX,mu1,logvar1,mu2,logvar2 = original_model(features)\n",
    "                    batch_loss,recon_loss,kl_loss = vae.vae_loss(reconX, labels.unsqueeze(1),mu1,logvar1,mu2,logvar2,self.vaeloss_coeff)\n",
    "                    val_loss+=batch_loss.item()\n",
    "                    val_reconloss+=recon_loss.item()\n",
    "                    val_klloss+=kl_loss.item()\n",
    "            \n",
    "                val_loss = val_loss / len(val_loader)\n",
    "                val_reconloss = val_reconloss / len(val_loader)\n",
    "                val_klloss = val_klloss / len(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "                valrecon_losses.append(val_reconloss)\n",
    "                valkl_losses.append(val_klloss)\n",
    "\n",
    "            # Check if the current model has the lowest validation loss\n",
    "            if val_loss < lowest_val_loss:\n",
    "                lowest_val_loss = val_loss\n",
    "                best_model = original_model#.state_dict()\n",
    "\n",
    "            if early_stopper:\n",
    "                if early_stopper.__call__(val_loss, original_model):\n",
    "                    break\n",
    "                \n",
    "            #torch.save(best_model, savefilepath+'vae/losscoeff_'+str(losscoeff)+'/'+str(splitnum)+'/modelstest'+str(splitnum)+'_vae_'+str(times[i])+'.pk')\n",
    "            torch.save(original_model.state_dict(), suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\n",
    "                       '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'modelstest_vae_'+str(exp)+'_best_weights.pk')\n",
    "            torch.save(best_model, suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\n",
    "                       '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'modelstest_vae_'+str(exp)+'_best.pk')\n",
    "            read_and_write.save_to_pickle({'trainALL':train_losses,'valALL':val_losses,'trainRECON':trainrecon_losses,'valRECON':valrecon_losses,'trainKL':trainkl_losses,'valKL':valkl_losses},\n",
    "                                          suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*'))[self.splitnum].split('/')[-1][startname:].split('.')[0])+\n",
    "                                          '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'lossestest_vae_'+str(exp)+'_best.pkt',\n",
    "                                        )\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b550472f-32fa-4a9b-96de-200feef84c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1a\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_410678/1618728581.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mearly_stopper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresume_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinue_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1e-14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5e-10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#    continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_410678/817565261.py\u001b[0m in \u001b[0;36mcontinue_training\u001b[0;34m(self, suffix, config_set, exp, scheduler_lr, early_stopper)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Transfer state dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         pretrained_model = torch.load(suffix+'storage/proc/VEDsmooth_9100/'+\\\n\u001b[0;32m---> 36\u001b[0;31m                                       \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../storage/proc/Xsmooth/9100/Xtimeseries*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstartname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                                       '/losscoeff_'+str(self.vaeloss_coeff)+'/'+'modelstest_vae_'+str(exp)+'.pk')[0]\n\u001b[1;32m     38\u001b[0m         \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for exp in ['exp1a','exp1b','exp1c','exp1d','exp1e','exp1f','exp1g','exp1h','exp1i']:#['a','b','c','d','e','f','g','h','i']:\n",
    "    print(exp)\n",
    "    early_stopper = vae.EarlyStopping(patience=1500, verbose=False, delta=1.5e-5, path='checkpoint.pt', trace_func=print)\n",
    "    resume_training(1,None,0.95,None,5,2).continue_training(config_set=config_set,exp=exp,scheduler_lr=[1e-14,5e-10],early_stopper=early_stopper)\n",
    "    #except:\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3486573d-b575-4997-bb2b-b29f660839a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003995656967163086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 48,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 16,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6af69984406437596ff96a5546710b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "suffix='/work/FAC/FGSE/IDYST/tbeucler/default/freddy0218/2024_TCG_VED_WRFsen/'\n",
    "for itime in tqdm([0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]): #1,17,18,19\n",
    "    fikes = glob.glob(suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[itime].split('/')[-1][17:].split('.')[0])+\n",
    "                      '/losscoeff_0/*')\n",
    "    filkenames = [obj.split('/')[-1] for obj in fikes]\n",
    "    for losscoeff in [0.9,0.65,0.55,0.45,0.35,0.3,0.25,0.95,0.85,0.8,0.75,0.7,0.6,0.5,0.4]:\n",
    "        [shutil.copy(suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[itime].split('/')[-1][17:].split('.')[0])+'/losscoeff_0/'+str(obsz),\n",
    "                     suffix+'storage/proc/VEDsmooth_9100/'+str(sorted(glob.glob('../../storage/proc/Xsmooth/9100/Xtimeseries*pkl'))[itime].split('/')[-1][17:].split('.')[0])+'/losscoeff_'+str(losscoeff)+'/'+str(obsz)) for obsz in filkenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14565048-297d-4a2a-a97b-dddbb0a4c9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
